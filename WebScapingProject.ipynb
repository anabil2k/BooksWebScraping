{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bff5a9a3-6090-40b6-8533-aba9c3de8fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task #1 Finished: Tags data has been extracted and saved to Extract_Text_Data.csv\n",
      "Task #2 Finished: Table data has been extracted and saved to Extract_Table_Data.csv\n",
      "Task #3 Finished: Product Information (Cards Section) has been extracted and saved to Product_Information.json\n",
      "Task #4 Finished: Form_Details have been extracted and saved to Form_Details.json\n",
      "Task #5 Finished: Multimedia links have been extracted and saved to Multimedia.json\n",
      "Task #6 Finished: featured_products have been Printed as folows and saved to featured_products.json\n",
      "[\n",
      "    {\n",
      "        \"id\": \"101\",\n",
      "        \"name\": \"Wireless Headphones\",\n",
      "        \"price\": \"$49.99\",\n",
      "        \"colors\": \"Available colors: Black, White, Blue\"\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"102\",\n",
      "        \"name\": \"Smart Speaker\",\n",
      "        \"price\": \"$89.99\",\n",
      "        \"colors\": \"Available colors: Grey, Black\"\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"103\",\n",
      "        \"name\": \"Smart Watch\",\n",
      "        \"price\": \"$149.99\",\n",
      "        \"colors\": \"Available colors: Black, Silver, Gold\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# Fetch the HTML page\n",
    "url = \"https://baraasalout.github.io/test.html\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "text_data = {}\n",
    "tags_to_extract = [\"p\", \"li\", \"h1\", \"h2\"]\n",
    "\n",
    "for tag in tags_to_extract:\n",
    "    text_data[tag] = [element.text.strip() for element in soup.find_all(tag)]\n",
    "\"\"\"\n",
    "# Task 1: Extract Text Data\n",
    "text_data = {\n",
    "    'h1': [h1.text.strip() for h1 in soup.find_all('h1')],\n",
    "    'h2': [h2.text.strip() for h2 in soup.find_all('h2')],\n",
    "    'p': [p.text.strip() for p in soup.find_all('p')],\n",
    "    'li': [li.text.strip() for li in soup.find_all('li')]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Save to CSV\n",
    "with open('Extract_Text_Data.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Tag Type', 'Content'])\n",
    "    for tag_type, contents in text_data.items():\n",
    "        for content in contents:\n",
    "            writer.writerow([tag_type, content])\n",
    "\n",
    "print(\"Task #1 Finished: Tags data has been extracted and saved to Extract_Text_Data.csv\")\n",
    "\n",
    "# Task 2: Extract Table Data\n",
    "table = soup.find('table')\n",
    "headers = [th.text.strip() for th in table.find_all('th')]\n",
    "rows = []\n",
    "for tr in table.find_all('tr')[1:]:  # Skip header row\n",
    "    cells = [td.text.strip() for td in tr.find_all('td')]\n",
    "    rows.append(dict(zip(headers, cells)))\n",
    "\n",
    "# Save to CSV\n",
    "with open('Extract_Table_Data.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(\"Task #2 Finished: Table data has been extracted and saved to Extract_Table_Data.csv\")\n",
    "\n",
    "# Task 3: Extract Product Information (Cards Section)\n",
    "cards = soup.find_all('div', style=\"text-align: center; width: 200px; border: 1px solid #ddd; padding: 10px; border-radius: 5px;\")\n",
    "products = []\n",
    "for card in cards:\n",
    "    product = {\n",
    "        'Book Title': card.find('strong').text.strip(),\n",
    "        'Price': card.find('p', style=\"color: green;\").text.strip(),\n",
    "        'Stock Availability': card.find('p', style=\"color: green;\").text.strip(),\n",
    "        'Button text': card.find('button').text.strip()\n",
    "    }\n",
    "    products.append(product)\n",
    "#print(json.dumps(products, indent=4))\n",
    "\n",
    "# Save to JSON\n",
    "with open('Product_Information.json', 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(products, jsonfile, indent=4)\n",
    "\n",
    "print(\"Task #3 Finished: Product Information (Cards Section) has been extracted and saved to Product_Information.json\")\n",
    "\n",
    "# Task 4: Extract Form Details\n",
    "form = soup.find('form')\n",
    "inputs = []\n",
    "for input_tag in form.find_all('input'):\n",
    "    input_data = {\n",
    "        'field_name': input_tag.get('name', ''),\n",
    "        'input_type': input_tag.get('type', ''),\n",
    "        'default_value': input_tag.get('value', '')\n",
    "    }\n",
    "    inputs.append(input_data)\n",
    "\n",
    "# Save to JSON\n",
    "with open('Form_Details.json', 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(inputs, jsonfile, indent=4)\n",
    "print(\"Task #4 Finished: Form_Details have been extracted and saved to Form_Details.json\")\n",
    "\n",
    "# Task 5: Extract Links and Multimedia\n",
    "iframe = soup.find('iframe')\n",
    "multimedia = {\n",
    "    'video_link': iframe.get('src', '') if iframe else ''\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open('Multimedia.json', 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(multimedia, jsonfile, indent=4)\n",
    "print(\"Task #5 Finished: Multimedia links have been extracted and saved to Multimedia.json\")\n",
    "\n",
    "# Task 6: Scraping Challenge (Featured Products)\n",
    "featured_products = []\n",
    "for product in soup.find_all('div', class_='product-card'):\n",
    "    featured_product = {\n",
    "        'id': product.get('data-id'),\n",
    "        'name': product.find('p', class_='name').text.strip(),\n",
    "        'price': product.find('p', class_='price').text.strip(),\n",
    "        'colors': product.find('p', class_='colors').text.strip()\n",
    "    }\n",
    "    featured_products.append(featured_product)\n",
    "\n",
    "print(\"Task #6 Finished: featured_products have been Printed as folows and saved to featured_products.json\")\n",
    "# Print challenge output\n",
    "print(json.dumps(featured_products, indent=4))\n",
    "# Save to JSON\n",
    "with open('featured_products.json', 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(featured_product, jsonfile, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33395302-e797-4fdc-b719-b0f31e324ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
